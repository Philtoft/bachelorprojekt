{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QGAR - A Flashcard Generating NLP Model\n",
    "\n",
    "This notebook shows how to load and use the `QGAR` model.\n",
    "\n",
    "Please read the [README](./readme.md) before continueing!\n",
    "\n",
    "**Table of Contents:**\n",
    "1. [Load QGAR](#load-qgar)\n",
    "2. [Download and Preprocess SQuAD Dataset](#download-and-preprocess-squad-dataset)\n",
    "3. [Run QGAR](#run-qgar)\n",
    "4. [Train QGAR](#4-train-qgar)\n",
    "\n",
    "</br>\n",
    "\n",
    "---\n",
    "\n",
    "</br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load QGAR\n",
    "First, we must load the `QGAR` model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/philiphyltoft/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from huggingface_hub import login\n",
    "from main import load_model_and_tokenizer, get_hg_token\n",
    "\n",
    "login(get_hg_token(), add_to_git_credential=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, tokenizer = load_model_and_tokenizer(\"the-coorporation/t5-qgar\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Preprocess SQuAD Dataset\n",
    "\n",
    "First, we download and preprocess the modified `SQuAD` dataset, adding separator (`<sep>`) and end of sequence tokens (`<\\s>`) to each entry.\n",
    "The preprocessed file is split in two datasets, `training` and `validation`, and the sets are saved in the `data` directory in `PyTorch` format under the names:\n",
    "* [training_data.pt](./data/training_data.pt)\n",
    "* [validation_data.pt](./data/validation_data.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading SQuAD dataset...\n",
      "Found cached dataset squad_processor (/Users/philiphyltoft/.cache/huggingface/datasets/squad_processor/plain_text/1.0.0/173b8305efd9aeaed82e2f74eb48fff367a5b6036cbf7fca6cd0deb4d4bb4f95)\n",
      "100%|██████████| 2/2 [00:00<00:00, 323.41it/s]\n",
      "Download complete.\n",
      "Preprocessing SQuAD dataset...\n",
      "Loading cached processed dataset at /Users/philiphyltoft/.cache/huggingface/datasets/squad_processor/plain_text/1.0.0/173b8305efd9aeaed82e2f74eb48fff367a5b6036cbf7fca6cd0deb4d4bb4f95/cache-bd6bdb3f24c6a457.arrow\n",
      "Loading cached processed dataset at /Users/philiphyltoft/.cache/huggingface/datasets/squad_processor/plain_text/1.0.0/173b8305efd9aeaed82e2f74eb48fff367a5b6036cbf7fca6cd0deb4d4bb4f95/cache-b8d3c00b5355c76b.arrow\n",
      "Loading cached processed dataset at /Users/philiphyltoft/.cache/huggingface/datasets/squad_processor/plain_text/1.0.0/173b8305efd9aeaed82e2f74eb48fff367a5b6036cbf7fca6cd0deb4d4bb4f95/cache-170928d4e07c8d49.arrow\n",
      "Loading cached processed dataset at /Users/philiphyltoft/.cache/huggingface/datasets/squad_processor/plain_text/1.0.0/173b8305efd9aeaed82e2f74eb48fff367a5b6036cbf7fca6cd0deb4d4bb4f95/cache-c53b6afe5389b59a.arrow\n",
      "Loading cached processed dataset at /Users/philiphyltoft/.cache/huggingface/datasets/squad_processor/plain_text/1.0.0/173b8305efd9aeaed82e2f74eb48fff367a5b6036cbf7fca6cd0deb4d4bb4f95/cache-e299d5eada15f7a6.arrow\n",
      "Loading cached processed dataset at /Users/philiphyltoft/.cache/huggingface/datasets/squad_processor/plain_text/1.0.0/173b8305efd9aeaed82e2f74eb48fff367a5b6036cbf7fca6cd0deb4d4bb4f95/cache-9ddeacb2c6a6c68a.arrow\n",
      "Done.\n",
      "Saving processed dataset to directory './data/'...\n",
      "Successfully saved processed datasets.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.preprocessor import Preprocessor\n",
    "\n",
    "preprocessor = Preprocessor(model, tokenizer)\n",
    "preprocessor.preprocess_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run QGAR\n",
    "Next, we import `QGAR` and set up a pipeline.\n",
    "Now, we can simply pass a context to the model to generate questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Input: 'Historical Fiction is one of those sub-genres of literature that takes many forms. It's most important feature, though, is that it's set in the past, with every element of the story conforming to the norms of the day. Here's how we define Historical Fiction, a look at its origins, and some popular types.'\n",
      "Output new: \n",
      "[' What is one of the sub-genres of literature that takes many forms?', 'What is the most important feature of Historical Fiction?', 'Where is Historical Fiction set in the past?', '</s']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from main import run_model\n",
    "\n",
    "input_text = \"Historical Fiction is one of those sub-genres of literature that takes many forms. It's most important feature, though, is that it's set in the past, with every element of the story conforming to the norms of the day. Here's how we define Historical Fiction, a look at its origins, and some popular types.\"\n",
    "\n",
    "questions = run_model(\"the-coorporation/t5-qgar\", device, input_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train QGAR\n",
    "To train `QGAR`, we first parse `settings.json` to get the training arguments.\n",
    "\n",
    "We then make an instance of `QGARTrainer` and call `train` which will train the model and push it to `The Coorporation`'s Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ModelArguments.__init__() missing 1 required positional argument: 'model_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./data/training_data.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m validation_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./data/validation_data.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m model_args, data_args, train_args \u001b[39m=\u001b[39m parse_settings()\n\u001b[1;32m      9\u001b[0m trainer \u001b[39m=\u001b[39m QGARTrainer(model, train_file, validation_file, train_args)\n\u001b[1;32m     10\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/MEGA/ITU/6sem/bachelorproject/bachelorprojekt/main.py:114\u001b[0m, in \u001b[0;36mparse_settings\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m     preprocessor = Preprocessor(model, tokenizer)\n\u001b[0;32m--> 114\u001b[0m     preprocessor.preprocess_dataset()\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m def get_hg_token() -> str:\n",
      "File \u001b[0;32m~/miniconda3/envs/hg_training/lib/python3.10/site-packages/transformers/hf_argparser.py:367\u001b[0m, in \u001b[0;36mHfArgumentParser.parse_dict\u001b[0;34m(self, args, allow_extra_keys)\u001b[0m\n\u001b[1;32m    365\u001b[0m     inputs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m args\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m keys}\n\u001b[1;32m    366\u001b[0m     unused_keys\u001b[39m.\u001b[39mdifference_update(inputs\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m--> 367\u001b[0m     obj \u001b[39m=\u001b[39m dtype(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m    368\u001b[0m     outputs\u001b[39m.\u001b[39mappend(obj)\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_extra_keys \u001b[39mand\u001b[39;00m unused_keys:\n",
      "\u001b[0;31mTypeError\u001b[0m: ModelArguments.__init__() missing 1 required positional argument: 'model_type'"
     ]
    }
   ],
   "source": [
    "from main import parse_settings\n",
    "from training.trainer import QGARTrainer\n",
    "\n",
    "train_file = \"./data/training_data.pt\"\n",
    "validation_file = \"./data/validation_data.pt\"\n",
    "\n",
    "model_args, data_args, train_args = parse_settings()\n",
    "\n",
    "trainer = QGARTrainer(model, train_file, validation_file, train_args)\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Answer Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['What is one of the sub-genres of literature that takes many forms?', 'What is the most important feature of Historical Fiction?', 'Where is Historical Fiction set in the past?', '?']\n",
      "[{'question': 'What is one of the sub-genres of literature that takes many forms?', 'answer': 'Historical Fiction', 'score': 0.9590075016021729}, {'question': 'What is the most important feature of Historical Fiction?', 'answer': \"it's set in the past\", 'score': 0.6126183271408081}, {'question': 'Where is Historical Fiction set in the past?', 'answer': 'every element of the story conforming to the norms of the day', 'score': 0.1702776700258255}, {'question': '?', 'answer': 'a look at its origins, and some popular types', 'score': 0.15543927252292633}]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "question_answers = []\n",
    "\n",
    "print(questions)\n",
    "\n",
    "for question in questions:\n",
    "    result = question_answerer(question=question, context=input_text)\n",
    "    question_answers.append({ \"question\": question, \"answer\": result[\"answer\"], \"score\": result[\"score\"] })\n",
    "\n",
    "print(question_answers)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae2ba95b8bc8fbec5d0ccff067e6f5791542bd91f96bfdb3bb5972317be5ea2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
