{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from evaluate.module import EvaluationModule\n",
    "from datasets import load_dataset, Dataset\n",
    "from models.qg import QG\n",
    "import torch\n",
    "\n",
    "qg = QG(\"the-coorporation/t5-small-qg-2.0\", \"the-coorporation/t5-small-qg-2.0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu: EvaluationModule = load(\"bleu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/laugu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/laugu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/laugu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "meteor: EvaluationModule = load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_squad_qg/v2\n",
      "Found cached dataset the_squad_qg (/home/laugu/.cache/huggingface/datasets/the-coorporation___the_squad_qg/v2/2.0.0/cd5e3386e9e3124c24114539fb5124093fa58d99c1a7292451b8801a94a2aca5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4d81058a8c46efae009e625df6b282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'questions'],\n",
       "    num_rows: 1204\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad: Dataset = load_dataset(\"the-coorporation/the_squad_qg\")\n",
    "validation = squad['validation']\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "references: list[dict] = [entry['questions'].replace(\" {sep_token}\", \"\") for entry in validation]\n",
    "\n",
    "predictions: list[dict] = []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "generator_args = {\n",
    "    \"max_length\": 512,\n",
    "    \"num_beams\": 4,\n",
    "    \"length_penalty\": 1.5,\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    \"early_stopping\": True,\n",
    "}\n",
    "\n",
    "\n",
    "for i, entry in enumerate(validation):\n",
    "    if i == 1:\n",
    "        break\n",
    "    \n",
    "    context: str = entry['context']\n",
    "    input_string = \"generate questions: \" + context + \" </s>\"\n",
    "\n",
    "    input_ids = qg._tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    result = qg._model.generate(input_ids, **generator_args).to(device)\n",
    "    questions = qg._tokenizer.decode(result[0], skip_special_tokens=True)\n",
    "    questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# p = predictions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# r = references\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# flat_list = [item for sublist in nested_list for item in sublist]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# p = [question for questions in predictions['questions'] for question in questions]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# p = [questions for questions in predictions['questions'] for prediction in predictions]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# p = [question for question in predictions['questions']]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m p \u001b[39m=\u001b[39m [question \u001b[39mfor\u001b[39;00m prediction \u001b[39min\u001b[39;00m predictions \u001b[39mfor\u001b[39;00m question \u001b[39min\u001b[39;00m prediction[\u001b[39m'\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m----> 8\u001b[0m r \u001b[39m=\u001b[39m [question \u001b[39mfor\u001b[39;00m reference \u001b[39min\u001b[39;00m references \u001b[39mfor\u001b[39;00m question \u001b[39min\u001b[39;00m reference[\u001b[39m'\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      9\u001b[0m rouge\u001b[39m.\u001b[39mcompute(references\u001b[39m=\u001b[39mr, predictions\u001b[39m=\u001b[39mp)\n",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# p = predictions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# r = references\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# flat_list = [item for sublist in nested_list for item in sublist]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# p = [question for questions in predictions['questions'] for question in questions]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# p = [questions for questions in predictions['questions'] for prediction in predictions]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# p = [question for question in predictions['questions']]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m p \u001b[39m=\u001b[39m [question \u001b[39mfor\u001b[39;00m prediction \u001b[39min\u001b[39;00m predictions \u001b[39mfor\u001b[39;00m question \u001b[39min\u001b[39;00m prediction[\u001b[39m'\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m----> 8\u001b[0m r \u001b[39m=\u001b[39m [question \u001b[39mfor\u001b[39;00m reference \u001b[39min\u001b[39;00m references \u001b[39mfor\u001b[39;00m question \u001b[39min\u001b[39;00m reference[\u001b[39m'\u001b[39;49m\u001b[39mquestions\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[1;32m      9\u001b[0m rouge\u001b[39m.\u001b[39mcompute(references\u001b[39m=\u001b[39mr, predictions\u001b[39m=\u001b[39mp)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# p = predictions\n",
    "# r = references\n",
    "# flat_list = [item for sublist in nested_list for item in sublist]\n",
    "# p = [question for questions in predictions['questions'] for question in questions]\n",
    "# p = [questions for questions in predictions['questions'] for prediction in predictions]\n",
    "# p = [question for question in predictions['questions']]\n",
    "p = [question for prediction in predictions for question in prediction['questions']]\n",
    "r = [question for reference in references for question in reference['questions']]\n",
    "rouge.compute(references=r, predictions=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hg_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
