{
	"model_arguments": {
		"qg_model_name": "t5-large",
		"tokenizer_name": "t5-large",
		"qa_model_name": "distilbert-base-cased-distilled-squad"
	},
	"data_training_arguments": {
		"training_file_path": "./data/training_data.pt",
		"validation_file_path": "./data/validation_data.pt",
		"wandb_project_name": "QG-large",
		"dataset": "the-coorporation/the_squad_qg",
		"dataset_output_dir": "data",
		"optimized_training": true,
		"upload_to_hub": true
	},
	"training_arguments": {
		"output_dir": "./model/t5-large-qg",
		"per_device_train_batch_size": 8,
		"per_device_eval_batch_size": 8,
		"gradient_accumulation_steps": 16,
		"learning_rate": 1e-4,
		"num_train_epochs": 10,
		"logging_steps": 100,
		"run_name": "With training optimizations",
		"evaluation_strategy": "steps",
		"save_steps": 500,
		"optim": "adafactor",
		"report_to": "wandb",
		"hub_model_id": "the-coorporation/t5-large-qg"
	}
}
