{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import QG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get parent directory\n",
    "notebook_path = os.path.abspath(\"evaluation.ipynb\")\n",
    "parent_dir = os.path.dirname(os.path.dirname(notebook_path))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\", 'questions': ['Who created Python?', 'When was Python first released?', \"What is Python's design philosophy?\"]}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.qg import QG\n",
    "\n",
    "context = \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\"\n",
    "\n",
    "qg = QG(model=\"valhalla/t5-base-e2e-qg\", tokenizer=\"t5-base\")\n",
    "\n",
    "contexts_questions = []\n",
    "\n",
    "result = qg(context)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Squad V2 and compare the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets -q\n",
    "%pip install pandas -q\n",
    "%pip install evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad_v2 (/Users/philiphyltoft/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n",
      "100%|██████████| 2/2 [00:00<00:00, 226.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# It needs \n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")[\"train\"].select(range(10))\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "df = df[[\"context\", \"question\"]]\n",
    "\n",
    "df = df.groupby(\"context\")['question'].apply(list).reset_index()\n",
    "\n",
    "# remove '\\n' and spaces from the context column\n",
    "# df['context'] = df['context'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "df['context'] = df['context'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "\n",
    "# Change column name from question to questions\n",
    "df.rename(columns={'question': 'references'}, inplace=True)\n",
    "\n",
    "# Split questions in validation questions column\n",
    "df['references'] = df['references'].apply(lambda x: [question for question in x])\n",
    "\n",
    "# Run QG on each context and insert into seperate column\n",
    "# df['generated_questions'] = df['context'].apply(lambda x: qg(x)['questions'])\n",
    "df['predictions'] = df['context'].apply(lambda x: [question for question in qg(x)['questions']])\n",
    "\n",
    "# Drop context column\n",
    "df = df.drop(columns=[\"context\"])\n",
    "\n",
    "result = df.to_dict(orient=\"records\")\n",
    "\n",
    "with open(\"output.json\", \"w\") as outfile:\n",
    "    json.dump(result, outfile, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run QGAR through each context and make it output questions.\n",
    "2. Compare the questions QGAR generates to the actually created questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run BLEU on generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources of Inspiration:\n",
    "- [BLEU score in Python - Beginners Overview](https://www.askpython.com/python/bleu-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'dog'], ['it', 'is', 'dog'], ['dog', 'it', 'is'], ['a', 'dog,', 'it', 'is']]\n",
      "BLEU score for test -> 1.2213386697554703e-77\n",
      "BLUE score for test2 -> 0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ref = [\n",
    "    'this is a dog'.split(),\n",
    "    'it is dog'.split(),\n",
    "    'dog it is'.split(),\n",
    "    'a dog, it is'.split() \n",
    "]\n",
    "\n",
    "print(ref)\n",
    "\n",
    "candidate = 'it is dog'.split()\n",
    "print('BLEU score for test -> {}'.format(sentence_bleu(ref, candidate)))\n",
    "test2 = 'why are you gay?'.split()\n",
    "print('BLUE score for test2 -> {}'.format(sentence_bleu(ref, test2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU implementation on QG's output\n",
    "It must for each context loop through each question generated and compare it to the expected output. But it has to split each sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE score is: 1.384292958842266e-231\n",
      "BLUE score is: 1.3659076482413118e-231\n",
      "BLUE score is: 1.2917956969975423e-231\n",
      "BLUE score is: 7.657404561915943e-155\n",
      "BLUE score is: 8.286571670851008e-155\n",
      "BLUE score is: 9.53091075863908e-155\n",
      "BLUE score is: 1.258141043412406e-231\n",
      "BLUE score is: 1.384292958842266e-231\n",
      "BLUE score is: 9.013778876140909e-155\n",
      "BLUE score is: 7.1958300848837144e-155\n"
     ]
    }
   ],
   "source": [
    "# Loop through each context\n",
    "with open(\"output.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for context in data:\n",
    "    for validation_question in context['references']:\n",
    "        print('BLUE score is: {}'.format(sentence_bleu(context['predictions'], validation_question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Beyonce', 'was', 'born', 'on', 'what', 'date?'], ['What', 'is', 'the', 'name', 'of', 'the', 'singer,', 'songwriter,', 'record', 'producer,', 'and', 'actress?'], ['Where', 'was', 'Beyoncé', 'born', 'and', 'raised?'], ['In', 'what', 'decade', 'did', 'she', 'rise', 'to', 'fame', 'as', 'the', 'lead', 'singer', 'of', \"Destiny's\", 'Child?'], ['How', 'many', 'Grammy', 'Awards', 'did', 'her', 'debut', 'album', 'earn?']]\n",
      "[['When', 'did', 'Beyonce', 'start', 'becoming', 'popular?'], ['What', 'areas', 'did', 'Beyonce', 'compete', 'in', 'when', 'she', 'was', 'growing', 'up?'], ['When', 'did', 'Beyonce', 'leave', \"Destiny's\", 'Child', 'and', 'become', 'a', 'solo', 'singer?'], ['In', 'what', 'city', 'and', 'state', 'did', 'Beyonce', 'grow', 'up?'], ['In', 'which', 'decade', 'did', 'Beyonce', 'become', 'famous?'], ['In', 'what', 'R&B', 'group', 'was', 'she', 'the', 'lead', 'singer?'], ['What', 'album', 'made', 'her', 'a', 'worldwide', 'known', 'artist?'], ['Who', 'managed', 'the', \"Destiny's\", 'Child', 'group?'], ['When', 'did', 'Beyoncé', 'rise', 'to', 'fame?'], ['What', 'role', 'did', 'Beyoncé', 'have', 'in', \"Destiny's\", 'Child?']]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import json\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "with open(\"output.json\", \"r\") as outputs:\n",
    "    outputs = json.load(outputs)\n",
    "    for output in outputs:\n",
    "        for item in output['predictions']:\n",
    "            predictions.append(item)\n",
    "        references.append(output['references'])\n",
    "\n",
    "print(predictions)\n",
    "print(references[0])\n",
    "\n",
    "# bleu = evaluate.load(\"bleu\")\n",
    "# results = bleu.compute(predictions=predictions, references=references[0])\n",
    "# print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. HuggingFace Evaluate library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use example with 2 metrics: [example link](https://huggingface.co/spaces/evaluate-metric/bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.0, 'precisions': [0.8571428571428571, 0.8, 0.6666666666666666, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.1666666666666667, 'translation_length': 7, 'reference_length': 6}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "predictions = [\"hello there general slut\", \"foo bar foobar\"]\n",
    "references = [[\"hello there general kenobi\", \"hello there !\"],[\"foo bar foobar\"]]\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['When', 'did', 'Beyonce', 'start', 'becoming', 'popular?'], ['What', 'areas', 'did', 'Beyonce', 'compete', 'in', 'when', 'she', 'was', 'growing', 'up?'], ['When', 'did', 'Beyonce', 'leave', \"Destiny's\", 'Child', 'and', 'become', 'a', 'solo', 'singer?'], ['In', 'what', 'city', 'and', 'state', 'did', 'Beyonce', 'grow', 'up?'], ['In', 'which', 'decade', 'did', 'Beyonce', 'become', 'famous?'], ['In', 'what', 'R&B', 'group', 'was', 'she', 'the', 'lead', 'singer?'], ['What', 'album', 'made', 'her', 'a', 'worldwide', 'known', 'artist?'], ['Who', 'managed', 'the', \"Destiny's\", 'Child', 'group?'], ['When', 'did', 'Beyoncé', 'rise', 'to', 'fame?'], ['What', 'role', 'did', 'Beyoncé', 'have', 'in', \"Destiny's\", 'Child?']]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"output.json\", \"r\") as output:\n",
    "    output1 = json.load(output)[0]\n",
    "    print(output1['validation_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hg_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
