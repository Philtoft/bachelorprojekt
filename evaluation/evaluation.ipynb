{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import QG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get parent directory\n",
    "notebook_path = os.path.abspath(\"evaluation.ipynb\")\n",
    "parent_dir = os.path.dirname(os.path.dirname(notebook_path))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\", 'questions': ['Who created Python?', 'When was Python first released?', \"What is Python's design philosophy?\"]}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.qg import QG\n",
    "\n",
    "context = \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\"\n",
    "\n",
    "qg = QG(model=\"valhalla/t5-base-e2e-qg\", tokenizer=\"t5-base\")\n",
    "\n",
    "contexts_questions = []\n",
    "\n",
    "result = qg(context)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Squad V2 and compare the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets -q\n",
    "%pip install pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad_v2 (/Users/philiphyltoft/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n",
      "100%|██████████| 2/2 [00:00<00:00, 210.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# It needs \n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")[\"train\"].select(range(10))\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "df = df[[\"context\", \"question\"]]\n",
    "\n",
    "df = df.groupby(\"context\")['question'].apply(list).reset_index()\n",
    "\n",
    "# remove '\\n' and spaces from the context column\n",
    "# df['context'] = df['context'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "df['context'] = df['context'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "\n",
    "# Change column name from question to questions\n",
    "df.rename(columns={'question': 'validation_questions'}, inplace=True)\n",
    "\n",
    "# Split questions in validation questions column\n",
    "df['validation_questions'] = df['validation_questions'].apply(lambda x: [question.split() for question in x])\n",
    "\n",
    "# Run QG on each context and insert into seperate column\n",
    "# df['generated_questions'] = df['context'].apply(lambda x: qg(x)['questions'])\n",
    "df['generated_questions'] = df['context'].apply(lambda x: [question.split() for question in qg(x)['questions']])\n",
    "\n",
    "result = df.to_dict(orient=\"records\")\n",
    "\n",
    "with open(\"output.json\", \"w\") as outfile:\n",
    "    json.dump(result, outfile, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run QGAR through each context and make it output questions.\n",
    "2. Compare the questions QGAR generates to the actually created questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run BLEU on generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources of Inspiration:\n",
    "- [BLEU score in Python - Beginners Overview](https://www.askpython.com/python/bleu-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for test -> 1.491668146240062e-154\n",
      "BLUE score for test2 -> 0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ref = [\n",
    "    'this is moonlight'.split(),\n",
    "    'Look, this is moonlight'.split(),\n",
    "    'moonlight it is'.split()\n",
    "]\n",
    "\n",
    "test = 'it is moonlight'.split()\n",
    "print('BLEU score for test -> {}'.format(sentence_bleu(ref, test)))\n",
    "test2 = 'why are you gay?'.split()\n",
    "print('BLUE score for test2 -> {}'.format(sentence_bleu(ref, test2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU implementation on QG's output\n",
    "It must for each context loop through each question generated and compare it to the expected output. But it has to split each sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE score is: 1.384292958842266e-231\n",
      "BLUE score is: 1.3659076482413118e-231\n",
      "BLUE score is: 1.2917956969975423e-231\n",
      "BLUE score is: 7.657404561915943e-155\n",
      "BLUE score is: 8.286571670851008e-155\n",
      "BLUE score is: 9.53091075863908e-155\n",
      "BLUE score is: 1.258141043412406e-231\n",
      "BLUE score is: 1.384292958842266e-231\n",
      "BLUE score is: 9.013778876140909e-155\n",
      "BLUE score is: 7.1958300848837144e-155\n"
     ]
    }
   ],
   "source": [
    "# Loop through each context\n",
    "with open(\"output.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for context in data:\n",
    "    for validation_question in context['validation_questions']:\n",
    "        print('BLUE score is: {}'.format(sentence_bleu(context['generated_questions'], validation_question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hg_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
